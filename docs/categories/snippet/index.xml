<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Snippet on Yu-Cheng Huang</title>
    <link>http://amoshyc.github.io/blog/categories/snippet.html</link>
    <description>Recent content in Snippet on Yu-Cheng Huang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 14 Jan 2019 01:21:36 +0800</lastBuildDate>
    
	<atom:link href="http://amoshyc.github.io/blog/categories/snippet/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Peek of 2D Heatmap</title>
      <link>http://amoshyc.github.io/blog/2019/peek-of-2d-heatmap.html</link>
      <pubDate>Mon, 14 Jan 2019 01:21:36 +0800</pubDate>
      
      <guid>http://amoshyc.github.io/blog/2019/peek-of-2d-heatmap.html</guid>
      <description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  def peek2d(lbl): &amp;#39;&amp;#39;&amp;#39; Args: lbl: (FloatTensor) sized [N, 4, H, W] Return: kpt: (FloatTensor) sized [N, 4, 2] &amp;#39;&amp;#39;&amp;#39; N, _, H, W = lbl.size() device = lbl.device lbl = lbl.view(N, 4, H * W) loc = lbl.argmax(dim=2) # [N, 4] yy, xx = loc / W, loc % W # [N, 4], [N, 4] kpt = torch.</description>
    </item>
    
    <item>
      <title>Reproducible PyTorch</title>
      <link>http://amoshyc.github.io/blog/2019/reproducible-pytorch.html</link>
      <pubDate>Thu, 10 Jan 2019 18:53:38 +0800</pubDate>
      
      <guid>http://amoshyc.github.io/blog/2019/reproducible-pytorch.html</guid>
      <description>將以下程式碼加在程式的 entry point，透過設定 seed 的方式，來讓整個訓練過程能夠複現。只在 pytorch 1.0 測試過，不保證其他版本也有相同效果。
1 2 3 4 5  seed = 999 random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) torch.backends.cudnn.deterministic = True   </description>
    </item>
    
    <item>
      <title>使用 Svgwrite 來可視化圖片</title>
      <link>http://amoshyc.github.io/blog/2018/visualization-with-svgwrite.html</link>
      <pubDate>Sun, 21 Oct 2018 00:27:00 +0800</pubDate>
      
      <guid>http://amoshyc.github.io/blog/2018/visualization-with-svgwrite.html</guid>
      <description>Introduction 許多 CV 問題都需要可視化，不管是可視化原始的資料，還是模型的預測結果，可視化總讓人能以直觀的方法了解你 code 有沒有寫錯，或模型是不是有什麼弱點。而有一大類的可視化不是生成圖表，而是必須在圖上標記，例如 Human Pose Estimation 與 Object Detection。
目前大家的做法是利用 OpenCV, Pillow 或 Skimage 直接把 edge, keypoint, text 畫在該圖片上，即直接修改該圖片的 pixel。也有不少人是用 matplotlib 來做可視化。但這兩種方法我都不太喜歡，後者是輸出的圖片會有各種留白，一直找不到方法把他們全部去掉；前者則有失真的問題：當你把圖片放大時，你會發現可視化的部份會變得模糊，線條尤為明顯，如下圖：
TODO
另外還有一些原因，上述的函式庫不容易畫出理想的圖形，例如 Skimage 畫不少太小的圓形、Pillow 沒法指定矩形的邊的粗細等等。為了解決這些問題（沒辦法，我就是受不了），我決定使用 svgwrite 來做這種「在圖片上標記」的可視化 1，也就是說我將圖片內嵌到 SVG 中，然後再加入一些 SVG 的 element，例如 Circle, Rect, Text 等來做可視化 2。
SVG 有著許多優點，例如他是向量圖形所以可視化部份不會有失真的問題，而且他內建的那個 element 有著許多參數可以調整，舉凡顏色、粗細等他都有著類似於 CSS 的一致 API，也因此，他可以使用半透明顏色。另外 SVG 內部可以使用 &amp;lt;g&amp;gt;&amp;lt;/g&amp;gt; 來任意嵌套，這在疊圖之類的事情還挺方便的。
這篇文的目的要記錄一些輔助我可視化函式，以防每次我都要重新想重新打，同時也給其他人參考。目前我是傾向使用 function-based 的設計而非 OOP，這樣在使用上會比較方便，這些函式應該全部放在同一個檔案，例如 svg.py 中，然後 import svg 來使用。
Basic Hint:
 g 可以任意嵌套 使用 x, y 而不是 r, c，原點在左上  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82  from math import ceil from io import BytesIO from base64 import b64encode import numpy as np from PIL import Image import svgwrite as sw def g(elems): &amp;#39;&amp;#39;&amp;#39; &amp;#39;&amp;#39;&amp;#39; g = sw.</description>
    </item>
    
    <item>
      <title>矩陣化加速計算向量之間的差</title>
      <link>http://amoshyc.github.io/blog/2018/speed-up-computing-difference-between-vectors.html</link>
      <pubDate>Wed, 03 Oct 2018 15:13:10 +0800</pubDate>
      
      <guid>http://amoshyc.github.io/blog/2018/speed-up-computing-difference-between-vectors.html</guid>
      <description>問題 給定維度 [N, D] 的矩陣 A，與 [M, D] 的矩陣 B，輸出維度 [N, M, D] 的矩陣 C，其中 C[i, j] 代表向量 A[i] 與向量 B[j] 的差，即 A[i] - B[j]。
矩陣化 最直覺的做法，兩個 for 迭代一下，簡單：
1 2 3  for i, a in enumerate(A): for j, b in enumerate(B): C[i, j] = a - b   但這個的計算速度非常非常慢，我們可以將這個計算改寫成矩陣的型式，讓 Numpy/Pytorch 可以利用 SIMD/GPU 來加速計算。
我們想讓結果是兩個矩陣 C1, C2 相減，即 C = C1 - C2，由此避掉大量的 indexing。其中，C1, C2 的維度都是 [N, M, D]。至此問題變成 C1, C2 分別是什麼。畫一下圖，發揮一下空間感，可以發現：</description>
    </item>
    
    <item>
      <title>Numpy 中實現二維高斯分佈</title>
      <link>http://amoshyc.github.io/blog/2018/implement-2d-gaussian-distribution-in-numpy.html</link>
      <pubDate>Sat, 03 Mar 2018 15:46:53 +0800</pubDate>
      
      <guid>http://amoshyc.github.io/blog/2018/implement-2d-gaussian-distribution-in-numpy.html</guid>
      <description>前情 最近讀了 Pose Estimation 相關的論文，發現一些 Bottom Up 的方法 1 2 會直接生成各個 Keypoints 會哪，中間不經過 RPN 等方法。而生成的 Confidence Map 的 Ground Truth 是使用高斯分佈 (Gaussian Distribution) 來指示位置。但我翻了一下文檔，numpy 似乎沒有提供生成二維高斯分佈的函式，只提供從高斯分佈取樣的函式，於是我模彷了 skimage.draw 的 API，寫了一個函式。
實作原理 二維高斯分佈就是兩個一維高斯分佈取外積。於是我分別對 row 與 col 各生成一個高斯分佈，函數 domain 為 $$ [sigma-3sigma, sigma+3sigma] $$，因為是整數域，共 $$ 6sigma + 1 $$ 個值。然後將這兩個分佈使用 np.outer 即為所求。
程式碼 Hint!  此函式不支援 double 型態的 mu 與 sigma！
  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  def gaussian2d(mu, sigma, shape=None): &amp;#34;&amp;#34;&amp;#34;Generate 2d gaussian distribution coordinates and values.</description>
    </item>
    
  </channel>
</rss>